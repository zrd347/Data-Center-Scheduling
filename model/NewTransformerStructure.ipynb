{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead, num_layers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "\n",
    "        # 定义Transformer编码器层\n",
    "        encoder_layers = nn.TransformerEncoderLayer(input_dim, nhead, dim_feedforward=512)\n",
    "        # 将多个编码器层堆叠成Transformer编码器\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        # 输入的线性层（编码器）\n",
    "        self.encoder = nn.Linear(input_dim, input_dim)\n",
    "        # 输出的线性层（解码器）\n",
    "        self.decoder = nn.Linear(input_dim, output_dim)\n",
    "        # Sigmoid激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, src):\n",
    "        # 初始输入形状为 (batch_size, sequence_length, input_dim)\n",
    "        batch_size, sequence_length, input_dim = src.size()\n",
    "\n",
    "        # 如果没有生成掩码或掩码的大小不等于序列长度，则生成一个新的掩码\n",
    "        if self.src_mask is None or self.src_mask.size(0) != sequence_length:\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(sequence_length).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        # 对输入数据进行线性变换编码\n",
    "        src = self.encoder(src)\n",
    "\n",
    "        # 将输入形状调整为 (sequence_length, batch_size, input_dim) 以匹配Transformer编码器的要求\n",
    "        src = src.permute(1, 0, 2)  # 调整形状\n",
    "        # 通过Transformer编码器层处理输入数据\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        \n",
    "        # 对编码器的输出进行线性变换解码\n",
    "        output = self.decoder(output)\n",
    "        # 添加sigmoid激活函数\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        # 将输出形状调整回 (batch_size, sequence_length, output_dim)\n",
    "        output = output.permute(1, 0, 2).contiguous()\n",
    "\n",
    "        # 调整输出形状为 (batch_size, 200, input_dim, 2, 60)\n",
    "        output = output.view(batch_size, 200, input_dim, 2, 60)\n",
    "        # 通过Sigmoid激活函数处理输出\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        # 生成一个大小为 sz x sz 的方形掩码矩阵\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        # 将掩码矩阵中上三角部分填充为0，其他部分填充为-inf\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "# 自定义二分类损失函数\n",
    "class BinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryCrossEntropyLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # 确保输出和目标的形状一致\n",
    "        outputs = outputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        loss = self.bce_loss(outputs, targets)\n",
    "        return loss\n",
    "\n",
    "# 训练部分示例\n",
    "def train_model(model, dataloader, num_epochs, learning_rate):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = BinaryCrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, targets)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 优化\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    print('训练完成')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
